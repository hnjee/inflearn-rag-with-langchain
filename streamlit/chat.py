import streamlit as st

import os
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_pinecone import PineconeVectorStore

st.set_page_config(page_title="ì†Œë“ì„¸ ì±—ë´‡", page_icon="ğŸ¤–")

st.title("ì†Œë“ì„¸ ì±—ë´‡ ğŸ¤–") #ì œëª© 
st.caption("ì†Œë“ì„¸ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”.")  #ìº¡ì…˜ ì„¤ëª… 

# st.chat_input(placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.") #ì±„íŒ… ì…ë ¥ ì°½ 
# st.chat_message("user"): #ì‚¬ìš©ì ë©”ì‹œì§€ ì°½ 
# st.chat_message("ai"): #ai ë©”ì‹œì§€ ì°½ 
# st.chat_message("assistant"): #assistant ë©”ì‹œì§€ ì°½ 
# st.chat_message("system"): #system ë©”ì‹œì§€ ì°½ 
# st.chat_message("error"): #error ë©”ì‹œì§€ ì°½ 

# with ë¬¸ì„ ì‚¬ìš©í•˜ë©´ ì•„ë˜ ë“¤ì—¬ì“°ê¸°ì— ìˆëŠ” ë‚´ìš©ì„ ì´ ì°½ ì•ˆì— ë„£ì–´ì¤Œ
# with st.chat_message("user"): #ì‚¬ìš©ì ë©”ì‹œì§€ ì°½ 
#     st.write("Hello, how are you?") #ì‚¬ìš©ì ë©”ì‹œì§€ ì°½ì— ë©”ì‹œì§€ ì¶œë ¥

#st.session_state
#streamlitì€ ì±„íŒ…ì„ ì…ë ¥í•  ë•Œë§ˆë‹¤ ì½”ë“œê°€ ì „ì²´ì ìœ¼ë¡œ ë‹¤ì‹œ ì‹¤í–‰ëœë‹¤.
#st.session_stateëŠ” ì½”ë“œê°€ ë‹¤ì‹œ ì‹¤í–‰ë˜ì–´ë„ ë°ì´í„°ë¥¼ ìœ ì§€í•´ì£¼ëŠ” íŠ¹ìˆ˜ ì €ì¥ì†Œ. (ìƒˆë¡œê³ ì¹¨ ì „ê¹Œì§€ íˆìŠ¤í† ë¦¬ ìœ ì§€)

if 'message_list' not in st.session_state:
    st.session_state.message_list = []

#ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ ì¶œë ¥
for message in st.session_state.message_list: 
    with st.chat_message(message["role"]):
        st.write(message["content"])

def get_ai_message(user_message):
    # 1. ì„ë² ë”©, ë²¡í„° DB ê°ì²´ ìƒì„± 
    load_dotenv()
    embedding = OpenAIEmbeddings(model='text-embedding-3-large')

    index_name = 'index-2'
    pinecone_api_key = os.environ.get("PINECONE_API_KEY")
    database = PineconeVectorStore.from_existing_index(
        index_name=index_name,
        embedding=embedding  # embedding ê°ì²´ëŠ” í•„ìš”
    )

    # 2. ì¿¼ë¦¬ ë³€í™˜ ì²´ì¸ ìƒì„±
    llm = ChatOpenAI(model="gpt-4o-mini")

    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]
    query_transform_prompt = ChatPromptTemplate.from_template(
        """ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , í‚¤ì›Œë“œ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”. 
        ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. 
        ê·¸ëŸ° ê²½ìš°ì—ëŠ” ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”.
        ì‚¬ì „: {dictionary}
        ì‚¬ìš©ìì˜ ì§ˆë¬¸: {question}
        """
    )
    query_transform_chain = (
        query_transform_prompt 
        | llm 
        | StrOutputParser()
    )

    # 3. RAG ê²€ìƒ‰ ì²´ì¸ ìƒì„±
    def format_docs(docs):
        """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í•˜ë‚˜ì˜ context ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
        return "\n\n---\n\n".join([doc.page_content for doc in docs])

    retriever = database.as_retriever(
        search_kwargs={"k": 3}
    )
    rag_prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ìµœê³ ì˜ í•œêµ­ ì†Œë“ì„¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                    ì£¼ì–´ì§„ contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”."""
        ),
        ("human", """Context: {context}
                    Question: {question}"""
        )
    ])
    rag_chain = (
        {
            "context": retriever | format_docs,  # ê²€ìƒ‰ í›„ í¬ë§·íŒ…
            "question": RunnablePassthrough()     # ì§ˆë¬¸ ê·¸ëŒ€ë¡œ ì „ë‹¬
        }
        | rag_prompt                              # í”„ë¡¬í”„íŠ¸ ìƒì„±
        | llm                                     # LLM í˜¸ì¶œ
        | StrOutputParser()                       # ë¬¸ìì—´ ì¶”ì¶œ
    )

    # 4. ì „ì²´ ì²´ì¸ ìƒì„±
    full_chain = query_transform_chain | rag_chain

    ai_message = full_chain.stream({
        "question": user_message, 
        "dictionary": dictionary
    })
    return ai_message

#ì±„íŒ… ì…ë ¥ ì°½ì— ì§ˆë¬¸ì´ ì…ë ¥ë˜ë©´ ìƒˆë¡œìš´ ë©”ì„¸ì§€ ì°½ ì¶”ê°€ 
if user_question := st.chat_input(placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."): 
    with st.chat_message("user"): # ì‚¬ìš©ì ë©”ì‹œì§€ ì°½ ìƒì„± 
        st.write(user_question)  
    st.session_state.message_list.append({"role": "user", "content": user_question}) #ì±„íŒ… ê¸°ë¡ ì¶”ê°€

    ai_message = get_ai_message(user_question)
    with st.chat_message("ai"): # ai ë©”ì‹œì§€ ì°½ ìƒì„± 
        st.write(ai_message)   
    st.session_state.message_list.append({"role": "ai", "content": ai_message}) #ì±„íŒ… ê¸°ë¡ ì¶”ê°€
